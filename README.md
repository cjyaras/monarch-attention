# MonarchAttention: Zero-Shot Conversion to Structured Attention in Transformer-Based Encoders
<p align="center">
  <img width="60%" src="flash_monarch.jpg">
</p>

Requires `python>=3.10`. How to run ViT benchmark:

```
./setup.sh
source .venv/bin/activate
python -m vit.benchmark
```
